"""
DAG –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
–í–∞—Ä–∏–∞–Ω—Ç –∑–∞–¥–∞–Ω–∏—è ‚Ññ30

–ê–≤—Ç–æ—Ä: Lee.A.A
–î–∞—Ç–∞: 13.10
"""

from datetime import datetime, timedelta
import pandas as pd
import json
import sqlite3
import os
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.operators.email_operator import EmailOperator
from airflow.utils.dates import days_ago

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è DAG
default_args = {
    'owner': 'student',
    'depends_on_past': False,
    'start_date': days_ago(1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'email': ['test@example.com']
}

# –°–æ–∑–¥–∞–Ω–∏–µ DAG
dag = DAG(
    'mobile_apps_retention_analysis',
    default_args=default_args,
    description='–ê–Ω–∞–ª–∏–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π',
    schedule_interval=timedelta(days=1),
    catchup=False,
    tags=['etl', 'mobile_apps', 'retention', 'variant_30']
)

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω—ã—Ö
DATA_DIR = '/opt/airflow/dags/data'
DB_PATH = '/opt/airflow/mobile_apps_retention.db'

def extract_apps_data(**context):
    """
    Extract: –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏–∑ CSV —Ñ–∞–π–ª–∞
    """
    print("–ù–∞—á–∏–Ω–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏–∑ CSV...")
    
    csv_path = os.path.join(DATA_DIR, 'employees.csv')
    
    try:
        # –ß—Ç–µ–Ω–∏–µ CSV —Ñ–∞–π–ª–∞
        employees_df = pd.read_csv(csv_path)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(employees_df)} –∑–∞–ø–∏—Å–µ–π –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö")
        print("–ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π:")
        print(employees_df.head())
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–¥–∞—á
        employees_data = employees_df.to_dict('records')
        context['task_instance'].xcom_push(key='employees_data', value=employees_data)
        
        print("–î–∞–Ω–Ω—ã–µ –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ XCom")
        return f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(employees_df)} –∑–∞–ø–∏—Å–µ–π –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö"
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö: {str(e)}")
        raise

def extract_installs_data(**context):
    """
    Extract: –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± —É—Å—Ç–∞–Ω–æ–≤–∫–∞—Ö –∏–∑ Excel —Ñ–∞–π–ª–∞
    """
    print("–ù–∞—á–∏–Ω–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± —É—Å—Ç–∞–Ω–æ–≤–∫–∞—Ö –∏–∑ Excel...")
    
    excel_path = os.path.join(DATA_DIR, 'training.xlsx')
    
    try:
        # –ß—Ç–µ–Ω–∏–µ Excel —Ñ–∞–π–ª–∞
        training_df = pd.read_excel(excel_path)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(training_df)} –∑–∞–ø–∏—Å–µ–π –æ–± —É—Å—Ç–∞–Ω–æ–≤–∫–∞—Ö")
        print("–ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π:")
        print(training_df.head())
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–¥–∞—á
        installs_data = training_df.to_dict('records')
        context['task_instance'].xcom_push(key='installs_data', value=installs_data)
        
        print("–î–∞–Ω–Ω—ã–µ –æ–± —É—Å—Ç–∞–Ω–æ–≤–∫–∞—Ö —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ XCom")
        return f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(training_df)} –∑–∞–ø–∏—Å–µ–π –æ–± —É—Å—Ç–∞–Ω–æ–≤–∫–∞—Ö"
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ–± —É—Å—Ç–∞–Ω–æ–≤–∫–∞—Ö: {str(e)}")
        raise

def extract_uninstalls_data(**context):
    """
    Extract: –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± —É–¥–∞–ª–µ–Ω–∏—è—Ö –∏–∑ JSON —Ñ–∞–π–ª–∞
    """
    print("–ù–∞—á–∏–Ω–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± —É–¥–∞–ª–µ–Ω–∏—è—Ö –∏–∑ JSON...")
    
    json_path = os.path.join(DATA_DIR, 'courses.json')
    
    try:
        # –ß—Ç–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞
        with open(json_path, 'r', encoding='utf-8') as f:
            courses_data = json.load(f)
        
        courses_df = pd.DataFrame(courses_data)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(courses_df)} –∑–∞–ø–∏—Å–µ–π –æ–± —É–¥–∞–ª–µ–Ω–∏—è—Ö")
        print("–ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π:")
        print(courses_df.head())
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–¥–∞—á
        context['task_instance'].xcom_push(key='courses_data', value=courses_data)
        
        print("–î–∞–Ω–Ω—ã–µ –æ–± —É–¥–∞–ª–µ–Ω–∏—è—Ö —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ XCom")
        return f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(courses_df)} –∑–∞–ø–∏—Å–µ–π –æ–± —É–¥–∞–ª–µ–Ω–∏—è—Ö"
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ–± —É–¥–∞–ª–µ–Ω–∏—è—Ö: {str(e)}")
        raise

def transform_data(**context):
    """
    Transform: –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞—Å—á–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è
    """
    print("–ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö...")
    



    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–¥–∞—á - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ò–ú–ï–ù–ê
        employees_data = context['task_instance'].xcom_pull(key='employees_data', task_ids='extract_apps')
        training_data = context['task_instance'].xcom_pull(key='installs_data', task_ids='extract_installs')
        courses_data = context['task_instance'].xcom_pull(key='courses_data', task_ids='extract_uninstalls')
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame
        employees_df = pd.DataFrame(employees_data)
        training_df = pd.DataFrame(training_data)
        courses_df = pd.DataFrame(courses_data)
        
        print("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ XCom")
        print(f"–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏: {len(employees_df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"–û–±—É—á–µ–Ω–∏–µ: {len(training_df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"–ö—É—Ä—Å—ã: {len(courses_df)} –∑–∞–ø–∏—Å–µ–π")
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        # –°–Ω–∞—á–∞–ª–∞ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å –æ–±—É—á–µ–Ω–∏–µ–º
        merged_df = pd.merge(employees_df, training_df, on='employee_id', how='inner')
        print(f"–ü–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å –æ–±—É—á–µ–Ω–∏–µ–º: {len(merged_df)} –∑–∞–ø–∏—Å–µ–π")
        
        # –ó–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –∫—É—Ä—Å–∞–º–∏
        final_df = pd.merge(merged_df, courses_df, on='course_id', how='inner')
        print(f"–ü–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å –∫—É—Ä—Å–∞–º–∏: {len(final_df)} –∑–∞–ø–∏—Å–µ–π")

        # –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–∏ –ø–æ –æ—Ç–¥–µ–ª–∞–º
        dept_stats = final_df.groupby('department').agg(
            total_employees=('employee_id', 'nunique'),
            total_courses=('course_id', 'count'),
            avg_score=('score', 'mean')
        ).reset_index()

        dept_stats['avg_score'] = dept_stats['avg_score'].round(2)

        print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –æ—Ç–¥–µ–ª–∞–º:")
        print(dept_stats)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î
        result_data = dept_stats.to_dict('records')
        context['task_instance'].xcom_push(key='dept_stats', value=result_data)
        
        print("–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(dept_stats)} –æ—Ç–¥–µ–ª–æ–≤"
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        raise






def load_to_database(**context):
    """
    Load: –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤ SQLite –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    """
    print("–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
    
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        dept_stats = context['task_instance'].xcom_pull(
            key='dept_stats', 
            task_ids='transform_data'
        )
        
        if not dept_stats:
            raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        dept_stats_df = pd.DataFrame(dept_stats)
        
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ SQLite –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        conn = sqlite3.connect(DB_PATH)
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            create_table_query = """
            CREATE TABLE IF NOT EXISTS retention_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                department TEXT NOT NULL,
                total_employees INTEGER NOT NULL,
                total_courses INTEGER NOT NULL,
                avg_score REAL NOT NULL,
                analysis_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            """
            conn.execute(create_table_query)
            
            # –û—á–∏—Å—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            conn.execute("DELETE FROM retention_analysis")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü—É
            dept_stats_df.to_sql('retention_analysis', conn, if_exists='append', index=False)
            
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            conn.commit()
            
            print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(dept_stats_df)} –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            verification_query = "SELECT * FROM retention_analysis ORDER BY avg_score DESC"
            result = pd.read_sql_query(verification_query, conn)
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
            print(result)
            
        finally:
            conn.close()
        
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dept_stats_df)} –∑–∞–ø–∏—Å–µ–π –≤ SQLite –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        raise










def generate_report(**context):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
    """
    print("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞...")
    
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        conn = sqlite3.connect(DB_PATH)
        
        try:
            query = """
            SELECT 
                department,
                total_employees,
                total_courses,
                avg_score
            FROM retention_analysis 
            ORDER BY avg_score DESC
            """
            
            result_df = pd.read_sql_query(query, conn)
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            report = f"""–û–¢–ß–ï–¢ –ü–û –ê–ù–ê–õ–ò–ó–£ –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢–ê –£–î–ï–†–ñ–ê–ù–ò–Ø –ú–û–ë–ò–õ–¨–ù–´–• –ü–†–ò–õ–û–ñ–ï–ù–ò–ô
================================================================

–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(result_df)}

–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:
"""
            
            for _, row in result_df.iterrows():
                report += f"""
department: {row['department']}

- –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ : {row['total_employees']:,}
- –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—É—Ä—Å–æ–≤: {row['total_courses']:,}
- —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª: {row['avg_score']:.2f}
"""
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            total_installs = result_df['total_employees'].sum()
            total_uninstalls = result_df['total_courses'].sum()
    
            report += f"""
–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
- –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å—Ç–∞–Ω–æ–≤–æ–∫: {total_installs:,}
- –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–∏–π: {total_uninstalls:,}


–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
"""
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
            best_department = result_df.iloc[0]
            worst_department = result_df.iloc[-1]
            
            report += f"""- –õ—É—á—à–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —É–¥–µ—Ä–∂–∞–Ω–∏—è —É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "{best_department['department']}" ({best_department['avg_score']:.2f})
- –¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è "{worst_department['department']}" ({worst_department['avg_score']:.2f})
- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑—É—á–∏—Ç—å —É—Å–ø–µ—à–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "{best_department['department']}"
"""
            
            print("–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω:")
            print(report)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–∞–π–ª
            report_file_path = '/opt/airflow/retention_analysis_report.txt'
            with open(report_file_path, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_file_path}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ CSV —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
            csv_file_path = '/opt/airflow/retention_analysis_data.csv'
            result_df.to_csv(csv_file_path, index=False, encoding='utf-8')
            print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {csv_file_path}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è email
            context['task_instance'].xcom_push(key='report', value=report)
            context['task_instance'].xcom_push(key='report_file_path', value=report_file_path)
            context['task_instance'].xcom_push(key='csv_file_path', value=csv_file_path)
            context['task_instance'].xcom_push(key='result_data', value=result_df.to_dict('records'))
            
        finally:
            conn.close()
            
        return "–û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª—ã"
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {str(e)}")
        raise

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á DAG

# Extract –∑–∞–¥–∞—á–∏
extract_apps_task = PythonOperator(
    task_id='extract_apps',
    python_callable=extract_apps_data,
    dag=dag,
    doc_md="""
    ### –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö
    –ß–∏—Ç–∞–µ—Ç CSV —Ñ–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏ –∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö.
    """
)

extract_installs_task = PythonOperator(
    task_id='extract_installs',
    python_callable=extract_installs_data,
    dag=dag,
    doc_md="""
    ### –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± —É—Å—Ç–∞–Ω–æ–≤–∫–∞—Ö
    –ß–∏—Ç–∞–µ—Ç Excel —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —É—Å—Ç–∞–Ω–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.
    """
)

extract_uninstalls_task = PythonOperator(
    task_id='extract_uninstalls',
    python_callable=extract_uninstalls_data,
    dag=dag,
    doc_md="""
    ### –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± —É–¥–∞–ª–µ–Ω–∏—è—Ö
    –ß–∏—Ç–∞–µ—Ç JSON —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —É–¥–∞–ª–µ–Ω–∏–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.
    """
)

# Transform –∑–∞–¥–∞—á–∞
transform_task = PythonOperator(
    task_id='transform_data',
    python_callable=transform_data,
    dag=dag,
    doc_md="""
    ### –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.
    """
)

# Load –∑–∞–¥–∞—á–∞
load_task = PythonOperator(
    task_id='load_to_database',
    python_callable=load_to_database,
    dag=dag,
    doc_md="""
    ### –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ SQLite –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
    """
)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
report_task = PythonOperator(
    task_id='generate_report',
    python_callable=generate_report,
    dag=dag,
    doc_md="""
    ### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    –°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è.
    """
)

def send_email_with_attachments(**context):
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ email —Å –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    from airflow.utils.email import send_email
    import os
    
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–¥–∞—á
        report = context['task_instance'].xcom_pull(key='report', task_ids='generate_report')
        result_data = context['task_instance'].xcom_pull(key='result_data', task_ids='generate_report')
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ HTML —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        html_content = f"""
        <h2> analysis average grade point after training for each </h2>
        
        <h3>üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏:</h3>
        <ul>
            <li><strong>DAG:</strong> average grade point after training for each</li>
            <li><strong>–î–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:</strong> {context['ds']}</li>
            <li><strong>–°—Ç–∞—Ç—É—Å:</strong> ‚úÖ –í—Å–µ –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –±–µ–∑ –æ—à–∏–±–æ–∫</li>
            <li><strong>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:</strong> –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö SQLite</li>
        </ul>
        
        <h3>üìà –ö—Ä–∞—Ç–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:</h3>
        <table border="1" style="border-collapse: collapse; width: 100%;">
            <tr style="background-color: #f2f2f2;">
                <th>department</th>
                <th>total_employees</th>
                <th>total_courses</th>
                <th>avg score</th>
            </tr>
        """
        
        if result_data:
            for row in result_data:
                html_content += f"""
            <tr>
                <td>{row['department']}</td>
                <td>{row['total_employees']:,}</td>
                <td>{row['total_courses']:,}</td>
                <td>{row['avg_score']:.2f}%</td>
            </tr>
                """
        
        html_content += """
        </table>
        
        <h3>üìé –ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:</h3>
        <ul>
            <li><strong>retention_analysis_report.txt</strong> - –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç</li>
            <li><strong>retention_analysis_data.csv</strong> - –î–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV</li>
        </ul>
        
        <p><em>–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Ç–∞–∫–∂–µ –¥–æ—Å—Ç—É–ø–µ–Ω –≤ –ª–æ–≥–∞—Ö –∑–∞–¥–∞—á–∏ generate_report –≤ Airflow UI.</em></p>
        
        <hr>
        <p style="color: #666; font-size: 12px;">
            –≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç —Å–∏—Å—Ç–µ–º—ã Apache Airflow<br>
            –í—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        </p>
        """
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        files = []
        report_file = '/opt/airflow/retention_analysis_report.txt'
        csv_file = '/opt/airflow/retention_analysis_data.csv'
        
        if os.path.exists(report_file):
            files.append(report_file)
            print(f"–î–æ–±–∞–≤–ª–µ–Ω —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏: {report_file}")
        
        if os.path.exists(csv_file):
            files.append(csv_file)
            print(f"–î–æ–±–∞–≤–ª–µ–Ω —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏: {csv_file}")
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ email
        send_email(
            to=['test@example.com'],
            subject='üìä –ê–Ω–∞–ª–∏–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã',
            html_content=html_content,
            files=files
        )
        
        print("Email —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        return "Email –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —Å –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏"
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ email: {str(e)}")
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –±–µ–∑ —Ñ–∞–π–ª–æ–≤
        send_email(
            to=['test@example.com'],
            subject='‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è - –ó–∞–≤–µ—Ä—à–µ–Ω (–±–µ–∑ —Ñ–∞–π–ª–æ–≤)',
            html_content=f"""
            <h3>–ê–Ω–∞–ª–∏–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —É–¥–µ—Ä–∂–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!</h3>
            <p>DAG: average grade point after training for each</p>
            <p>–î–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {context['ds']}</p>
            <p>–í—Å–µ –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –±–µ–∑ –æ—à–∏–±–æ–∫.</p>
            <p><strong>–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:</strong> –§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {str(e)}</p>
            <p>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –ª–æ–≥–∞—Ö –∑–∞–¥–∞—á–∏ generate_report.</p>
            """
        )
        raise

# Email —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å —Ñ–∞–π–ª–∞–º–∏
email_task = PythonOperator(
    task_id='send_email_notification',
    python_callable=send_email_with_attachments,
    dag=dag,
    doc_md="""
    ### –û—Ç–ø—Ä–∞–≤–∫–∞ email-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç email —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏.
    """
)

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏
# Extract –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
[extract_apps_task, extract_installs_task, extract_uninstalls_task] >> transform_task

# Transform -> Load -> Report -> Email (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)
transform_task >> load_task >> report_task >> email_task
